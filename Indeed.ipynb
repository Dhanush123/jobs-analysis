{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bsoup, Tag\n",
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Position, Title, Description, Url]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed_mle_csv = \"indeed/indeed_mle.csv\"\n",
    "df = pd.read_csv(indeed_mle_csv)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveWebpage(prefix,response):\n",
    "    \"\"\"Save webpage locally as HTML and returns file location as string\"\"\"\n",
    "    now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H.%M\")\n",
    "    doc_name = \"indeed/{prefix}_{time}.html\".format(prefix=prefix,time=now)\n",
    "    #https://stackoverflow.com/questions/31126596/saving-response-from-requests-to-file\n",
    "    with open(doc_name, mode=\"wb+\") as localfile:\n",
    "        localfile.write(response.content)\n",
    "    return doc_name\n",
    "\n",
    "def getUrlsFromPage(website,params,prefix):\n",
    "    response = requests.request(\"GET\", website, params=params)\n",
    "    page_location = saveWebpage(prefix,response)\n",
    "    soup = bsoup(open(page_location), \"html.parser\")\n",
    "    raw_urls = soup.find_all(\"a\",class_=\"turnstileLink\")\n",
    "    print(len(soup.find(\"div\",class_=\"pagination\").findChildren(\"a\",recursive=False)))\n",
    "    more_urls = True if soup.find(\"div\",class_=\"pagination\").findChildren(\"a\",recursive=False,limit=1) else False\n",
    "    return raw_urls, more_urls\n",
    "\n",
    "def makeUrlsVisitable(urls):\n",
    "    visitable_urls = []\n",
    "    #other endpoints I found are /pagead and /cmp\n",
    "    acceptable_endpoints = [\"rc\"]\n",
    "    #https://stackoverflow.com/questions/36300158/python-split-text-after-the-second-occurrence-of-character\n",
    "    for url in urls:\n",
    "        if (type(url) is Tag and (url[\"href\"].split(\"/\", 2))[1] in acceptable_endpoints):\n",
    "            visitable_urls.append(\"https://www.indeed.com\"+url[\"href\"])\n",
    "    return visitable_urls\n",
    "    \n",
    "\n",
    "def getAllUrls(website,params,prefix):\n",
    "    page_num = 0\n",
    "    all_urls = set()\n",
    "    page_urls, more_urls = getUrlsFromPage(website,params,prefix)\n",
    "    if page_urls:\n",
    "        print(\"page {page_num}: {urls_on_page} urls on page\".format(page_num=1,urls_on_page=len(page_urls)))\n",
    "        u = makeUrlsVisitable(page_urls)\n",
    "        for url in u:\n",
    "            all_urls.add(url)\n",
    "        while more_urls and page_num < 5: #self rate limiting\n",
    "            params[\"start\"] = str(int(params[\"start\"])+50) #get next 50 results\n",
    "            page_urls, more_urls = getUrlsFromPage(website,params,prefix)\n",
    "            page_num += 1\n",
    "#             print(\"page {page_num}: {urls_on_page} urls on page\".format(page_num=page_num,urls_on_page=len(page_urls)))\n",
    "            u = makeUrlsVisitable(page_urls)\n",
    "            for url in u:\n",
    "                all_urls.add(url)\n",
    "            time.sleep(2)\n",
    "    return all_urls\n",
    "    \n",
    "    \n",
    "def getJobsData(urls):\n",
    "    \"\"\"Gets job data from each url and returns Numpy matrix of data\"\"\"\n",
    "    data = np.array([])\n",
    "    return data\n",
    "    \n",
    "def saveJobsData(data):\n",
    "    \"\"\"Saves jobs data to Pandas dataframe and from there to CSV file\"\"\"\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "page 1: 60 urls on page\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "251\n"
     ]
    }
   ],
   "source": [
    "#get MLE data\n",
    "website = \"https://www.indeed.com/jobs\"\n",
    "# mle_params = {\"q\":\"machine+learning+engineer\",\"l\":\"San+Francisco+Bay+Area,+CA\",\"explvl\":\"entry_level\"}\n",
    "mle_params = {\"as_and\":\"machine learning engineer\",\"as_phr\":\"\",\"as_any\":\"\",\"as_not\":\"\",\"as_ttl\":\"\",\"as_cmp\":\"\",\"jt\":\"all\",\"st\":\"\",\"as_src\":\"\",\"salary\":\"\",\"radius\":\"25\",\"l\":\"San Francisco Bay Area, CA\",\"fromage\":\"any\",\"limit\":\"50\",\"sort\":\"\",\"psf\":\"advsrch\",\"start\":\"0\"}\n",
    "mle_prefix = \"mle\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = getAllUrls(website,mle_params,mle_prefix)\n",
    "#https://stackoverflow.com/questions/8466014/how-to-convert-a-python-set-to-a-numpy-array\n",
    "urls = list(urls)\n",
    "num_urls = len(urls)\n",
    "print(num_urls)\n",
    "for url in urls:\n",
    "    df.loc[len(df)] = [None,None,None,url.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=a4b96f68e3358...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=874c931eda801...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=6db9ecef73f21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=cbeae73193a4c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=99b1587ae9242...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=68d2210334775...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=85b912f3f9cd7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=4dec418aecacc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=9a2eca4654e14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=4094194e91b8e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Position Title Description  \\\n",
       "0     None  None        None   \n",
       "1     None  None        None   \n",
       "2     None  None        None   \n",
       "3     None  None        None   \n",
       "4     None  None        None   \n",
       "5     None  None        None   \n",
       "6     None  None        None   \n",
       "7     None  None        None   \n",
       "8     None  None        None   \n",
       "9     None  None        None   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://www.indeed.com/rc/clk?jk=a4b96f68e3358...  \n",
       "1  https://www.indeed.com/rc/clk?jk=874c931eda801...  \n",
       "2  https://www.indeed.com/rc/clk?jk=6db9ecef73f21...  \n",
       "3  https://www.indeed.com/rc/clk?jk=cbeae73193a4c...  \n",
       "4  https://www.indeed.com/rc/clk?jk=99b1587ae9242...  \n",
       "5  https://www.indeed.com/rc/clk?jk=68d2210334775...  \n",
       "6  https://www.indeed.com/rc/clk?jk=85b912f3f9cd7...  \n",
       "7  https://www.indeed.com/rc/clk?jk=4dec418aecacc...  \n",
       "8  https://www.indeed.com/rc/clk?jk=9a2eca4654e14...  \n",
       "9  https://www.indeed.com/rc/clk?jk=4094194e91b8e...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(indeed_mle_csv, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.indeed.com/rc/clk?jk=a4b96f68e3358b32&fccid=f89deb5a97c7738a&vjs=3'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][\"Url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "# # mle_params = {\"as_and\":\"machine learning engineer\",\"as_phr\":\"\",\"as_any\":\"\",\"as_not\":\"\",\"as_ttl\":\"\",\"as_cmp\":\"\",\"jt\":\"all\",\"st\":\"\",\"as_src\":\"\",\"salary\":\"\",\"radius\":\"25\",\"l\":\"San Francisco Bay Area, CA\",\"fromage\":\"any\",\"limit\":\"50\",\"sort\":\"\",\"psf\":\"advsrch\",\"start\":\"0\"}\n",
    "# response = requests.get(\"https://www.indeed.com/jobs?q=machine+learning+engineer&explvl=entry_level\", headers = headers)\n",
    "\n",
    "# soup = BeautifulSoup(response.text,'lxml')\n",
    "\n",
    "# #This will you all a tags in div that has pagination class\n",
    "# pages = soup.find(\"div\",class_='pagination').findChildren(\"a\",recursive=False,limit=1)\n",
    "# \"res\",pages\n",
    "# import requests\n",
    "\n",
    "# url = \"https://www.indeed.com/jobs\"\n",
    "\n",
    "# querystring = {\"as_and\":\"machine+learning+engineer\",\"as_phr\":\"\",\"as_any\":\"\",\"as_not\":\"\",\"as_ttl\":\"\",\"as_cmp\":\"\",\"jt\":\"all\",\"st\":\"\",\"as_src\":\"\",\"salary\":\"\",\"radius\":\"25\",\"l\":\"San+Francisco+Bay+Area%2C+CA\",\"fromage\":\"any\",\"limit\":\"50\",\"sort\":\"\",\"psf\":\"advsrch\"}\n",
    "\n",
    "# headers = {\n",
    "#     'cache-control': \"no-cache\",\n",
    "#     'Postman-Token': \"3e4c7fb2-cfc6-4b86-8351-e605858228b1\"\n",
    "#     }\n",
    "\n",
    "# response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "# soup = BeautifulSoup(response.text,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTV Machine Learning Engineer Intern\n"
     ]
    }
   ],
   "source": [
    "test = bsoup(requests.get(df.iloc[0][\"Url\"]).text, \"html.parser\")\n",
    "print(test.find(\"h3\",class_=\"icl-u-xs-mb--xs icl-u-xs-mt--none jobsearch-JobInfoHeader-title\").string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
