{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bsoup, Tag\n",
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "import webbrowser as browser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "chrome_path = \"open -a /Applications/Google\\ Chrome.app %s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Description</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Position, Description, Url]\n",
       "Index: []"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed_mle_csv = \"indeed/indeed_mle.csv\"\n",
    "df = pd.read_csv(indeed_mle_csv)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveWebpage(prefix,response):\n",
    "    \"\"\"Save webpage locally as HTML and returns file location as string\"\"\"\n",
    "    now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H.%M\")\n",
    "    doc_name = \"indeed/{prefix}_{time}.html\".format(prefix=prefix,time=now)\n",
    "    #https://stackoverflow.com/questions/31126596/saving-response-from-requests-to-file\n",
    "    with open(doc_name, mode=\"wb+\") as localfile:\n",
    "        localfile.write(response.content)\n",
    "    return doc_name\n",
    "\n",
    "def getUrlsFromPage(website,params,prefix):\n",
    "    response = requests.request(\"GET\", website, params=params)\n",
    "    page_location = saveWebpage(prefix,response)\n",
    "    soup = bsoup(open(page_location), \"html.parser\")\n",
    "    raw_urls = soup.find_all(\"a\",class_=\"turnstileLink\")\n",
    "#     print(len(soup.find(\"div\",class_=\"pagination\").findChildren(\"a\",recursive=False)))\n",
    "    more_urls = True if soup.find(\"div\",class_=\"pagination\").findChildren(\"a\",recursive=False,limit=1) else False\n",
    "    return raw_urls, more_urls\n",
    "\n",
    "def makeUrlsVisitable(urls):\n",
    "    visitable_urls = []\n",
    "    #other endpoints I found are /pagead and /cmp\n",
    "    acceptable_endpoints = [\"rc\"]\n",
    "    #https://stackoverflow.com/questions/36300158/python-split-text-after-the-second-occurrence-of-character\n",
    "    for url in urls:\n",
    "        if (type(url) is Tag and (url[\"href\"].split(\"/\", 2))[1] in acceptable_endpoints):\n",
    "            visitable_urls.append(\"https://www.indeed.com\"+url[\"href\"])\n",
    "    return visitable_urls\n",
    "    \n",
    "\n",
    "def getAllUrls(website,params,prefix):\n",
    "    page_num = 0\n",
    "    all_urls = set()\n",
    "    page_urls, more_urls = getUrlsFromPage(website,params,prefix)\n",
    "    if page_urls:\n",
    "        print(\"page {page_num}: {urls_on_page} urls on page\".format(page_num=1,urls_on_page=len(page_urls)))\n",
    "        u = makeUrlsVisitable(page_urls)\n",
    "        for url in u:\n",
    "            all_urls.add(url)\n",
    "        while more_urls and page_num < 5: #self rate limiting\n",
    "            params[\"start\"] = str(int(params[\"start\"])+50) #get next 50 results\n",
    "            page_urls, more_urls = getUrlsFromPage(website,params,prefix)\n",
    "            page_num += 1\n",
    "#             print(\"page {page_num}: {urls_on_page} urls on page\".format(page_num=page_num,urls_on_page=len(page_urls)))\n",
    "            u = makeUrlsVisitable(page_urls)\n",
    "            for url in u:\n",
    "                all_urls.add(url)\n",
    "            time.sleep(1)\n",
    "    return all_urls\n",
    "    \n",
    "    \n",
    "def getJobsData(urls):\n",
    "    \"\"\"Gets job data from each url and returns Numpy matrix of data\"\"\"\n",
    "    data = np.array([])\n",
    "    return data\n",
    "    \n",
    "def saveJobsData(data):\n",
    "    \"\"\"Saves jobs data to Pandas dataframe and from there to CSV file\"\"\"\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get MLE data\n",
    "website = \"https://www.indeed.com/jobs\"\n",
    "# mle_params = {\"q\":\"machine+learning+engineer\",\"l\":\"San+Francisco+Bay+Area,+CA\",\"explvl\":\"entry_level\"}\n",
    "# mle_params = {\"as_and\":\"\",\"as_phr\":\"Machine+Learning+Engineer\",\"as_any\":\"\",\"as_not\":\"\",\"as_ttl\":\"\",\n",
    "#               \"as_cmp\":\"\",\"jt\":\"fulltime\",\"st\":\"\",\"as_src\":\"\",\"salary\":\"\",\"radius\":\"50\",\n",
    "#               \"l\":\"San+Francisco+Bay+Area%2C+CA\",\"fromage\":\"any\",\"limit\":\"50\",\"sort\":\"\",\"psf\":\"advsrch\",\"start\":\"0\"}\n",
    "\n",
    "mle_params = {\"as_and\":\"\",\"as_phr\":\"Machine+Learning+Engineer\",\"as_any\":\"\",\"as_not\":\"\",\n",
    " \"as_ttl\":\"\",\"as_cmp\":\"\",\"jt\":\"fulltime\",\"st\":\"\",\"as_src\":\"\",\"salary\":\"\",\"radius\":\"50\",\"l\":\"San Francisco Bay Area, CA\",\n",
    " \"fromage\":\"any\",\"limit\":\"50\",\"sort\":\"\",\"psf\":\"advsrch\",\"start\":\"0\"}\n",
    "\n",
    "# {\"as_and\":\"Machine+Learning+Engineer\",\"as_phr\":\"Machine+Learning+Engineer\",\"as_any\":\"\",\"as_not\":\"\",\n",
    "#               \"as_ttl\":\"\",\"as_cmp\":\"\",\"jt\":\"fulltime\",\"st\":\"\",\"as_src\":\"\",\"salary\":\"\",\"radius\":\"50\",\n",
    "#               \"l\":\"San+Francisco+Bay+Area%2C+CA\",\"fromage\":\"any\",\"limit\":\"50\",\"sort\":\"\",\"psf\":\"advsrch\"}\n",
    "mle_prefix = \"mle\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 1: 58 urls on page\n",
      "156\n"
     ]
    }
   ],
   "source": [
    "urls = getAllUrls(website,mle_params,mle_prefix)\n",
    "#https://stackoverflow.com/questions/8466014/how-to-convert-a-python-set-to-a-numpy-array\n",
    "urls = list(urls)\n",
    "num_urls = len(urls)\n",
    "print(num_urls)\n",
    "for url in urls:\n",
    "    df.loc[len(df)] = [None,None,url.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(indeed_mle_csv, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/rc/clk?jk=ae20548c6763d6e4&fccid=ae6e171391e978d5&vjs=3\n",
      "https://www.indeed.com/rc/clk?jk=2f995bb9c1a1df6b&fccid=6e9166ecf7604472&vjs=3\n",
      "https://www.indeed.com/rc/clk?jk=09e77269e281ba5e&fccid=849cecf89c5fe512&vjs=3\n",
      "https://www.indeed.com/rc/clk?jk=1848b64b8db92063&fccid=3433aab0a6573d98&vjs=3\n",
      "https://www.indeed.com/rc/clk?jk=47f8abbfe2603d8e&fccid=7d28c1874e2d22be&vjs=3\n",
      "https://www.indeed.com/rc/clk?jk=c0930d01caa5d3be&fccid=c8100afc42779772&vjs=3\n",
      "https://www.indeed.com/rc/clk?jk=fc7fe4fac36fc39d&fccid=cee5eb240fcda90f&vjs=3\n",
      "https://www.indeed.com/rc/clk?jk=fcd8f59113385b5d&fccid=e490ccf806951166&vjs=3\n",
      "https://www.indeed.com/rc/clk?jk=75cf426272cffb60&fccid=4027cfd917e1ee29&vjs=3\n",
      "https://www.indeed.com/rc/clk?jk=6979e0f72b393b02&fccid=f89deb5a97c7738a&vjs=3\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    url = df.iloc[i][\"Url\"]\n",
    "    print(url)\n",
    "    browser.get(chrome_path).open_new_tab(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/36864690/iterate-through-a-dataframe-by-index\n",
    "for i, row in df.iterrows():\n",
    "    url = row[\"Url\"]\n",
    "    page = bsoup(requests.get(df.iloc[i][\"Url\"]).text, \"html.parser\")\n",
    "    df.iloc[i][\"Position\"] = page.find(\"h3\",class_=\"icl-u-xs-mb--xs icl-u-xs-mt--none jobsearch-JobInfoHeader-title\").string\n",
    "    df.iloc[i][\"Description\"] = page.find(\"div\",class_=\"jobsearch-JobComponent-description icl-u-xs-mt--md\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Description</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>What is Pathrise?\\nPathrise (YC W18) invests i...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=ae20548c6763d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>CircleUp harnesses the power of machine learni...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=2f995bb9c1a1d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Applied Machine Learning Engi...</td>\n",
       "      <td>The world runs on software. Yet delivering cha...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=09e77269e281b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine Learning Engineer - Recommendation Ser...</td>\n",
       "      <td>At Change we are a unique blend of engineers, ...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=1848b64b8db92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Software Engineer - Machine Learning</td>\n",
       "      <td>About Bill.com\\nBill.com is the leading busine...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=47f8abbfe2603...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sr. Machine Learning Engineer / Data Scientist...</td>\n",
       "      <td>About Us\\n\\nTuro is a peer-to-peer car sharing...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=c0930d01caa5d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>We are looking for an experienced Software Eng...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=fc7fe4fac36fc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>At Toyota Research Institute (TRI), we’re work...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=fcd8f59113385...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead or Principal Machine Learning Engineer</td>\n",
       "      <td>Job Category\\nSalesforce.org - Products and Te...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=75cf426272cff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Full Stack, Software Engineer</td>\n",
       "      <td>The challenge\\nIn the mission towards continuo...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=6979e0f72b393...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Position  \\\n",
       "0                   Senior Machine Learning Engineer   \n",
       "1                          Machine Learning Engineer   \n",
       "2  Data Scientist - Applied Machine Learning Engi...   \n",
       "3  Machine Learning Engineer - Recommendation Ser...   \n",
       "4        Senior Software Engineer - Machine Learning   \n",
       "5  Sr. Machine Learning Engineer / Data Scientist...   \n",
       "6                   Senior Machine Learning Engineer   \n",
       "7                          Machine Learning Engineer   \n",
       "8        Lead or Principal Machine Learning Engineer   \n",
       "9                      Full Stack, Software Engineer   \n",
       "\n",
       "                                         Description  \\\n",
       "0  What is Pathrise?\\nPathrise (YC W18) invests i...   \n",
       "1  CircleUp harnesses the power of machine learni...   \n",
       "2  The world runs on software. Yet delivering cha...   \n",
       "3  At Change we are a unique blend of engineers, ...   \n",
       "4  About Bill.com\\nBill.com is the leading busine...   \n",
       "5  About Us\\n\\nTuro is a peer-to-peer car sharing...   \n",
       "6  We are looking for an experienced Software Eng...   \n",
       "7  At Toyota Research Institute (TRI), we’re work...   \n",
       "8  Job Category\\nSalesforce.org - Products and Te...   \n",
       "9  The challenge\\nIn the mission towards continuo...   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://www.indeed.com/rc/clk?jk=ae20548c6763d...  \n",
       "1  https://www.indeed.com/rc/clk?jk=2f995bb9c1a1d...  \n",
       "2  https://www.indeed.com/rc/clk?jk=09e77269e281b...  \n",
       "3  https://www.indeed.com/rc/clk?jk=1848b64b8db92...  \n",
       "4  https://www.indeed.com/rc/clk?jk=47f8abbfe2603...  \n",
       "5  https://www.indeed.com/rc/clk?jk=c0930d01caa5d...  \n",
       "6  https://www.indeed.com/rc/clk?jk=fc7fe4fac36fc...  \n",
       "7  https://www.indeed.com/rc/clk?jk=fcd8f59113385...  \n",
       "8  https://www.indeed.com/rc/clk?jk=75cf426272cff...  \n",
       "9  https://www.indeed.com/rc/clk?jk=6979e0f72b393...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(indeed_mle_csv, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rakuten Intelligence is looking for a Data Scientist / Machine Learning Engineer to join our Information Extraction team.\n",
      "\n",
      "The Information Extraction team at Slice is responsible for using machine learning to build the world's largest cross-merchant purchase graph from email. We build engines for email classification and field extraction. We leverage existing open source technologies and established machine learning approaches, but also innovate and research new techniques. And of course, we do all this at a large scale: hundreds of billions of documents.\n",
      "\n",
      "As a data scientist / machine learning engineer, you will spend a mix of your time researching new solutions for information extraction as well as productionizing these solutions to make sure they work at scale. You will work with world-class data scientists who hold MS/PhD degrees from top global schools such as Stanford University, University of Washington, Carnegie Mellon University, and National Taiwan University, and veterans from companies such as Microsoft, AOL, Yahoo!, and Twitter.\n",
      "\n",
      "Rakuten Intelligence was founded by proven entrepreneurs and, as a Rakuten group company, offers the best of both worlds: a start­up environment with the backing of an established global enterprise that is revolutionizing the internet services landscape.\n",
      "\n",
      "This position will be located in San Mateo or New York.\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "Research and experiment with different machine learning algorithms and techniques to find structure in unstructured documents\n",
      "Conduct design and code reviews\n",
      "Productionize the developed Machine Learning solutions\n",
      "Work with engineers to make sure the engines scale well on high volumes of data\n",
      "\n",
      "Requirements:\n",
      "\n",
      "MS/PhD in Computer Science or a related field\n",
      "3+ years of industry experience in data science and machine learning preferred\n",
      "Expertise in Machine Learning\n",
      "Strong CS fundamentals, such as algorithms and data structures\n",
      "Expertise in Python\n",
      "Proficiency with relational databases such as MySQL\n",
      "Experience with cloud computing stacks such as Amazon Web Services preferred\n",
      "Excellent written and verbal communication skills\n",
      "Enthusiasm for working hard and having fun in a dynamic environment\n",
      "\n",
      "Who We Are:\n",
      "Rakuten Intelligence is transforming e-commerce by unveiling never-before-seen e-commerce insights. Rakuten Intelligence has developed a technology that extracts commerce data from emails to make it actionable for brands, retailers, and investors. With the largest panel of online shoppers under measurement, Rakuten Intelligence provides the most detailed, accurate, and actionable e-commerce data available, and is the most cited source on e-commerce by the media.\n",
      "\n",
      "Our Mission:\n",
      "Empowering Rakuten's global community of members and merchants through amazing apps and the most robust e-commerce data.\n",
      "\n",
      "Our Values:\n",
      "BOLD: When we go beyond what exists today or is accepted as possible, we create breakthrough products that deliver amazing benefits.\n",
      "\n",
      "SIMPLE: Solving hard problems is in our DNA. Eliminating complexity paves the road to clean thinking and decisive action that can move mountains.\n",
      "\n",
      "OPEN: Openness and transparency are critical for building trust. We are a community of curious people who are open to new ideas and fresh approaches to solving problems.\n",
      "\n",
      "ALL IN: When we are empowered, show up, and dig deep, our work is powerful and rewarding. We are committed, accountable, and take extreme ownership.\n",
      "\n",
      "Healthy and Fun Work Environment:\n",
      "Various drinks and snacks, breakfast and lunch served daily, adjustable sit/stand desks, company social and volunteer events, commuter benefits, fitness reimbursements, and on-site gym.\n"
     ]
    }
   ],
   "source": [
    "temp = bsoup(requests.get(df.iloc[0][\"Url\"]).text, \"html.parser\")\n",
    "print(page.find(\"div\",class_=\"jobsearch-JobComponent-description icl-u-xs-mt--md\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
